{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b146376364ec4850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:17:06.871953Z",
     "start_time": "2024-06-14T11:17:05.887182Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, concatenate_datasets, Dataset\n",
    "from IPython.display import display\n",
    "\n",
    "#import torchaudio\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import gc\n",
    "import soundfile as sf\n",
    "import IPython\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "#import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb152d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip uninstall -y torch\\n!pip install torch==2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip uninstall -y torch\n",
    "!pip install torch==2.4.1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c910258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa78cbf0c1a49689da63ad77612c9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73873249f6e049e19bb59d94f5c9cf34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eda49f35d1045e3b9b96bae0395a228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'text', 'source', 'speaker_id', 'denoised_audio'],\n",
       "        num_rows: 22910\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset splits\n",
    "dataset = load_dataset(\"ArissBandoss/moore-tts-full-dataset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "788f7784839b3d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:17:16.381971Z",
     "start_time": "2024-06-14T11:17:12.359727Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'text', 'source', 'speaker_id', 'denoised_audio', 'lang'],\n",
       "        num_rows: 22910\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].add_column('lang', ['mos'] * len(dataset['train'])) #.rename_column(\"transcription\", \"text\")\n",
    "#dataset['train'] = dataset['train'].add_column('speaker_id', ['1'] * len(dataset['train']))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab957c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = dataset.rename_column(\"denoised_audio\", \"denoised\")\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e79663c64d5a8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:17:41.314624Z",
     "start_time": "2024-06-14T11:17:41.309666Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_audio_file(example, audio_column, output_dir, index):\n",
    "    \"\"\"\n",
    "    Creates a single audio file from the 'audio' column of an example and returns the file path.\n",
    "    \"\"\"\n",
    "    # Construct the output file path\n",
    "    audio_filename = f\"audio_{index}.wav\"\n",
    "    audio_filepath = os.path.join(output_dir, audio_filename)\n",
    "\n",
    "    # If file does not exist, write the audio data to the file\n",
    "    if not os.path.isfile(audio_filepath):\n",
    "        # Extract audio data and sample rate from the example\n",
    "        audio_data = example[audio_column]['array']\n",
    "        sample_rate = example[audio_column]['sampling_rate']\n",
    "\n",
    "        # Save the audio file\n",
    "        sf.write(audio_filepath, audio_data, sample_rate)\n",
    "\n",
    "    #return {\"audio_file_path\": audio_filepath}\n",
    "    return {\"audio_filename\": audio_filename}\n",
    "\n",
    "\n",
    "\n",
    "def batch_create_audio_files_and_update_dataset(dataset, audio_column, output_dir):\n",
    "    \"\"\"\n",
    "    Maps over the dataset, creates audio files and updates the dataset with the file paths.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Use the .map() function to process the dataset and create audio files\n",
    "    dataset_with_audio_paths = dataset.map(\n",
    "        lambda example, idx: create_audio_file(example, audio_column, output_dir, idx),\n",
    "        with_indices=True,  # Pass example indices to the map function\n",
    "        num_proc=32\n",
    "    )\n",
    "\n",
    "    return dataset_with_audio_paths\n",
    "\n",
    "\n",
    "\n",
    "def create_audio_files_and_update_dataset(dataset, audio_column, output_dir):\n",
    "    \"\"\"\n",
    "    Create audio files from the 'audio' column of a Hugging Face dataset and update the dataset with file paths.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The input dataset that contains the 'audio' column.\n",
    "    - audio_column: The name of the column containing the audio data (datasets.Audio feature).\n",
    "    - output_dir: The directory where audio files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - The updated dataset with the 'audio' column containing the file paths of saved audio files.\n",
    "    \"\"\"\n",
    "    # Make sure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Prepare a list to hold the file paths, to avoid modifying the dataset in-place\n",
    "    #audio_file_paths = []\n",
    "    audio_file_names = []\n",
    "\n",
    "    for index, example in tqdm(enumerate(dataset), total=len(dataset), desc=\"Creating audio files\", unit=\"file\"):\n",
    "        audio_filename = f\"audio_{index}.wav\"\n",
    "        audio_filepath = os.path.join(output_dir, audio_filename)\n",
    "\n",
    "        if os.path.isfile(audio_filepath):\n",
    "            audio_file_paths.append(audio_filepath)\n",
    "            continue\n",
    "\n",
    "        audio_data = example[audio_column]['array']\n",
    "        # Typically, the sample rate should also be retrieved from the dataset\n",
    "        sample_rate = example[audio_column]['sampling_rate']\n",
    "\n",
    "        # Save the audio file\n",
    "        #sf.write(audio_filepath, audio_data, sample_rate)\n",
    "        sf.write(audio_filename, audio_data, sample_rate)\n",
    "\n",
    "        # Append the file path to the list\n",
    "        #audio_file_paths.append(audio_filepath)\n",
    "        audio_file_names.append(audio_filename)\n",
    "\n",
    "        # Option to clear memory if needed, uncomment if large arrays are involved\n",
    "        del audio_data\n",
    "        gc.collect()\n",
    "\n",
    "    # Update the dataset with the new file paths\n",
    "    #dataset = dataset.add_column(\"audio_file_path\", audio_file_paths)\n",
    "    dataset = dataset.add_column(\"audio_filename\", audio_filename)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Function to create the metadata file\n",
    "def create_metadata_file(dataset, output_dir='MyTTSDataSet', filename='metadata.csv'):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Define the path to the metadata file\n",
    "    metadata_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Open the metadata file in write mode\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        # Iterate over each item in the dataset\n",
    "        f.write(f\"audio_file|text|speaker_name\\n\")\n",
    "        for item in dataset:\n",
    "            # Your dataset should have an 'audio' column with a dictionary containing the file path and 'array' for the audio data\n",
    "            #audio_path = item['audio_file_path'].replace(\".wav\", \"\")\n",
    "            audio_filename = item['audio_filename']\n",
    "            text = item['text'].replace(\" \", \" \").replace(\" \", \" \").replace(\"\\n\", \" \").replace(\"\\\\\", \" \")\n",
    "            normalized_text = text\n",
    "            speaker_id = item['speaker_id']\n",
    "            lang = item['lang']\n",
    "\n",
    "            # Write the formatted data to the metadata file\n",
    "            f.write(f\"wavs/{audio_filename}|{str(text)}|{str(speaker_id)}\\n\")\n",
    "\n",
    "    return metadata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0644fe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dir1 = \"/teamspace/studios/this_studio/mosXTTS/dataset/wavs/\"\\n\\ndata1 = batch_create_audio_files_and_update_dataset(\\n    dataset, audio_column=\"denoised_audio\",\\n    output_dir=dir1\\n)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dir1 = \"/teamspace/studios/this_studio/mosXTTS/dataset/wavs/\"\n",
    "\n",
    "data1 = batch_create_audio_files_and_update_dataset(\n",
    "    dataset, audio_column=\"denoised_audio\",\n",
    "    output_dir=dir1\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed418b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c51d4db36c45dcbc649c0a0ad4ff94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/22910 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = \"/teamspace/studios/this_studio/mosXTTS/dataset/wavs/\"\n",
    "\n",
    "data = batch_create_audio_files_and_update_dataset(\n",
    "    dataset, audio_column=\"denoised_audio\",\n",
    "    output_dir=dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8601b6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'text', 'source', 'speaker_id', 'denoised_audio', 'lang', 'audio_filename'],\n",
       "        num_rows: 22910\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.shuffle(2024)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6362b069800e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:18:58.562483Z",
     "start_time": "2024-06-14T11:18:58.556098Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'text', 'source', 'speaker_id', 'denoised_audio', 'lang', 'audio_filename'],\n",
       "        num_rows: 20619\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'text', 'source', 'speaker_id', 'denoised_audio', 'lang', 'audio_filename'],\n",
       "        num_rows: 2291\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = data[\"train\"].train_test_split(test_size=0.1, seed=2024)\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8e1376e5babb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:19:02.545795Z",
     "start_time": "2024-06-14T11:19:01.980039Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/mosXTTS/dataset/metadata_val.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"/teamspace/studios/this_studio/mosXTTS/dataset\"\n",
    "\n",
    "create_metadata_file(dataset_dict['train'], output_dir=dataset_path, filename='metadata.csv')\n",
    "create_metadata_file(dataset_dict['test'],  output_dir=dataset_path, filename='metadata_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0cd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
