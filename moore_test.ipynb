{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "from TTS.tts.layers.xtts.tokenizer import VoiceBpeTokenizer\n",
    "import re\n",
    "\n",
    "# Device configuration\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Model paths\n",
    "xtts_checkpoint = \"/teamspace/studios/this_studio/mosXTTS/checkpoints/GPT_XTTS_FT-September-27-2024_11+12AM-8526b4f/best_model_51560.pth\"\n",
    "xtts_config = \"/teamspace/studios/this_studio/mosXTTS/checkpoints/XTTS_v2.0_original_model_files/config.json\"\n",
    "xtts_vocab = \"/teamspace/studios/this_studio/mosXTTS/checkpoints/XTTS_v2.0_original_model_files/vocab.json\"\n",
    "\n",
    "\n",
    "def split_moore_sentences(text):\n",
    "    # Define sentence-ending punctuation patterns\n",
    "    sentence_endings = re.compile(r'(?<=[.!?])\\s+')\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = sentence_endings.split(text)\n",
    "    \n",
    "    # Clean up any leading/trailing spaces and filter out empty strings\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6681,\n",
       " 1500,\n",
       " 25,\n",
       " 2,\n",
       " 6893,\n",
       " 6705,\n",
       " 2,\n",
       " 31,\n",
       " 48,\n",
       " 2,\n",
       " 27,\n",
       " 2,\n",
       " 7225,\n",
       " 6705,\n",
       " 2,\n",
       " 2772,\n",
       " 8,\n",
       " 799,\n",
       " 1779,\n",
       " 2,\n",
       " 494,\n",
       " 2,\n",
       " 7060,\n",
       " 1159]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_text = \"\"\"sull kãnga rat n sõnga kom-biisa la pagba\"\"\"\n",
    "\n",
    "tokenizer = VoiceBpeTokenizer(vocab_file=xtts_vocab)\n",
    "ids = tokenizer.encode(tts_text, \"mos\")\n",
    "print(len(ids))\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[mos]sull kãnga rat n sõnga kom-biisa la pagba'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = XttsConfig()\n",
    "config.load_json(xtts_config)\n",
    "XTTS_MODEL = Xtts.init_from_config(config)\n",
    "XTTS_MODEL.load_checkpoint(config, \n",
    "    checkpoint_path=xtts_checkpoint, \n",
    "    vocab_path=xtts_vocab, \n",
    "    use_deepspeed=False)\n",
    "    \n",
    "XTTS_MODEL.to(device)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sull kãnga rat n sõnga kom-biisa la pagba']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "speaker_audio_file = \"/teamspace/studios/this_studio/mosXTTS/reference_1_speaker_male_17.wav\"\n",
    "lang = \"mos\"\n",
    "\n",
    "gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(\n",
    "    audio_path=speaker_audio_file,\n",
    "    gpt_cond_len=XTTS_MODEL.config.gpt_cond_len,\n",
    "    max_ref_length=XTTS_MODEL.config.max_ref_len,\n",
    "    sound_norm_refs=XTTS_MODEL.config.sound_norm_refs,\n",
    ")\n",
    "\n",
    "tts_texts = split_moore_sentences(tts_text)\n",
    "tts_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1006, 1000, 1011, 1012,  996,  710,  855,  985, 1002,  132,   96,   75,\n",
      "          690,  161,  387,  297,   52,  389,  464,   80,  230,  326,   50,  252,\n",
      "          173,  587,  410,  489,  619,   10,  718,  646,  906,  209,  210,  276,\n",
      "          371,  839,  135,  674,  417,   55,  781,    6,  426,  350,   35,   89,\n",
      "          310,   86,  570,  341,  445,  502, 1016,  648,  612,  785,  896,  959,\n",
      "          976,  465,  989,  950,  990,  747,  178,  501,   18,   12,   83,  623,\n",
      "          193,  725,  176,  345,    7,  626,  357,  478, 1014,  607,  490,  237,\n",
      "          811,  972,  991,  964,  821,  993,  987, 1025]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4.2487e-04, 4.4983e-05, 9.7052e-05,  ..., 2.8408e-04, 2.6621e-04,\n",
       "         6.3133e-05]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_chunks = []\n",
    "for text in tqdm(tts_texts):\n",
    "    wav_chunk = XTTS_MODEL.inference(\n",
    "        text=text,\n",
    "        language=lang,\n",
    "        gpt_cond_latent=gpt_cond_latent,\n",
    "        speaker_embedding=speaker_embedding,\n",
    "        temperature=0.1,\n",
    "        length_penalty=1.0,\n",
    "        repetition_penalty=10.0,\n",
    "        top_k=10,\n",
    "        top_p=0.3,\n",
    "    )\n",
    "    wav_chunks.append(torch.tensor(wav_chunk[\"wav\"]))\n",
    "\n",
    "out_wav = torch.cat(wav_chunks, dim=0).unsqueeze(0).cpu()\n",
    "out_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"/teamspace/studios/this_studio/mosXTTS/audio_tests/test_33.wav\", out_wav, 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from IPython.display import Audio\\n\\nAudio(out_wav.numpy(), rate=24000)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from IPython.display import Audio\n",
    "\n",
    "Audio(out_wav.numpy(), rate=24000)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ArissBandoss/coqui-tts-moore-V1/commit/ed15407329529589d5a83fe360ba41152563e3ea', commit_message='Upload folder using huggingface_hub', commit_description='', oid='ed15407329529589d5a83fe360ba41152563e3ea', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ArissBandoss/coqui-tts-moore-V1', endpoint='https://huggingface.co', repo_type='model', repo_id='ArissBandoss/coqui-tts-moore-V1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi(token=\"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\")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"/teamspace/studios/this_studio/mosXTTS/TTS\",\n",
    "    path_in_repo=\"/TTS\",\n",
    "    repo_id=\"ArissBandoss/coqui-tts-moore-V1\",\n",
    "    repo_type=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c429e9c96304c559207fa86dacabcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.tar.gz:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ArissBandoss/coqui-tts-moore-V1/commit/a0bd70b0fd59f27f993341ba7c30c58bb085e3a0', commit_message='Upload model.tar.gz with huggingface_hub', commit_description='', oid='a0bd70b0fd59f27f993341ba7c30c58bb085e3a0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ArissBandoss/coqui-tts-moore-V1', endpoint='https://huggingface.co', repo_type='model', repo_id='ArissBandoss/coqui-tts-moore-V1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi(token=\"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\")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/teamspace/studios/this_studio/mosXTTS/deploy_folder/model.tar.gz\",\n",
    "    path_in_repo=\"model.tar.gz\",\n",
    "    repo_id=\"ArissBandoss/coqui-tts-moore-V1\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fb9fbbeb0d46efb5ccd9633f0d58e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dvae.safetensors:   0%|          | 0.00/211M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ArissBandoss/coqui-tts-moore-V1/commit/be8d002b3ef86c2f9d80ceadd5031b538603b589', commit_message='Upload dvae.safetensors with huggingface_hub', commit_description='', oid='be8d002b3ef86c2f9d80ceadd5031b538603b589', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ArissBandoss/coqui-tts-moore-V1', endpoint='https://huggingface.co', repo_type='model', repo_id='ArissBandoss/coqui-tts-moore-V1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi(token=\"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\")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/teamspace/studios/this_studio/mosXTTS/models/converted_safetensors/dvae.safetensors\",\n",
    "    path_in_repo=\"dvae.safetensors\",\n",
    "    repo_id=\"ArissBandoss/coqui-tts-moore-V1\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
